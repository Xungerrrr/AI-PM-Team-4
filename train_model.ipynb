{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eUPA4uDQwzaH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5AncyPNzxk8I"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9YZnE0Hvxr45",
    "outputId": "fa75b1da-1f01-4b47-fa26-74280bae4042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRems9R6BSeY",
    "outputId": "1e7e759c-31e5-413d-cf38-67b4b5e26010"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/chenzixuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chenzixuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chenzixuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\n",
      "Collecting contractions\n",
      "  Using cached contractions-0.1.68-py2.py3-none-any.whl (8.1 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Using cached textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.4-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting anyascii\n",
      "  Using cached anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\n",
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.68 pyahocorasick-1.4.4 textsearch-0.0.21\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "%pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s-eOGKxA3vgk"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        articles = articles.lower()\n",
    "\n",
    "        for p in string.punctuation:\n",
    "          articles = articles.replace(p, ' ')\n",
    "        \n",
    "        articles = contractions.fix(articles)\n",
    "        \n",
    "        res = []\n",
    "        _stopwords = set(stopwords.words('english'))\n",
    "        for t in word_tokenize(articles):\n",
    "          token = self.wnl.lemmatize(t) \n",
    "          if token in _stopwords:\n",
    "            continue\n",
    "          res.append(token)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XyzJGwadxuK2"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "\n",
    "dict_name = \"own_dict.txt\"\n",
    "# Try to load dictionary\n",
    "if os.path.exists(dict_name):\n",
    "    with open(dict_name, 'r') as f:\n",
    "        own_dict = [word for word in f.readlines()]\n",
    "else:\n",
    "    # Build a dictionary according to word frequency\n",
    "    vectorizer = CountVectorizer(tokenizer=Tokenizer())\n",
    "\n",
    "    train_text = raw_data['question_text']\n",
    "    labels = raw_data['target']\n",
    "\n",
    "    train_vec = vectorizer.fit_transform(train_text)\n",
    "\n",
    "    word_count = train_vec.sum(axis=0)\n",
    "    word_count = np.asarray(word_count).reshape((1,-1))\n",
    "    feature_names = vectorizer.get_feature_names_out().reshape(-1)\n",
    "    word_count = pd.DataFrame(word_count, columns=feature_names)\n",
    "\n",
    "    word_count.T.sort_values(by=0, ascending=False)\n",
    "\n",
    "    word_count_sorted = word_count.T.sort_values(by=0, ascending=False)\n",
    "    word_count_sorted.columns = [\"count\"]\n",
    "\n",
    "    # filter all words that have <=150 frequency\n",
    "    filter_index = sum(word_count_sorted[\"count\"] > 150)\n",
    "    own_dict = list(word_count_sorted.index[:filter_index])\n",
    "\n",
    "    with open(dict_name, 'w') as f:\n",
    "        for word in own_dict:\n",
    "            f.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "C9N8P99_zD4z",
    "outputId": "058b015c-d0c6-4443-ba90-cb5f1816f254"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>787627</th>\n",
       "      <td>9a4e197b444e8a341614</td>\n",
       "      <td>Why do Chinese Quora users strongly believe th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238013</th>\n",
       "      <td>f29d4bc51fee4bbb3631</td>\n",
       "      <td>Where does it clearly and specifically say in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621867</th>\n",
       "      <td>79c4ae9f40f9bbca1efa</td>\n",
       "      <td>What is the meaning of TQWL7/WL4 in 3A, and wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155178</th>\n",
       "      <td>1e5a90b1c7833e020209</td>\n",
       "      <td>Why north Americans are less cultural than peo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807188</th>\n",
       "      <td>9e2a320c121db8ac9ad6</td>\n",
       "      <td>What's one thing you did to get your life back...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145386</th>\n",
       "      <td>1c724fcc1ad47671e8d7</td>\n",
       "      <td>What are some of the ways God tests us nowaday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298359</th>\n",
       "      <td>3a6c1fddf7de2e28b82b</td>\n",
       "      <td>By the way Indians and Chinese hate them selfs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123644</th>\n",
       "      <td>dc31da9587985c921fe2</td>\n",
       "      <td>Why are some people so blinded as to what kind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947768</th>\n",
       "      <td>b9b87f20a1c7cbb6e33a</td>\n",
       "      <td>What are the benefits of eating celery leaves?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>00373e104379306a7fbf</td>\n",
       "      <td>Approximately how long should it take for some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "787627   9a4e197b444e8a341614   \n",
       "1238013  f29d4bc51fee4bbb3631   \n",
       "621867   79c4ae9f40f9bbca1efa   \n",
       "155178   1e5a90b1c7833e020209   \n",
       "807188   9e2a320c121db8ac9ad6   \n",
       "...                       ...   \n",
       "145386   1c724fcc1ad47671e8d7   \n",
       "298359   3a6c1fddf7de2e28b82b   \n",
       "1123644  dc31da9587985c921fe2   \n",
       "947768   b9b87f20a1c7cbb6e33a   \n",
       "1121     00373e104379306a7fbf   \n",
       "\n",
       "                                             question_text  target  \n",
       "787627   Why do Chinese Quora users strongly believe th...       1  \n",
       "1238013  Where does it clearly and specifically say in ...       1  \n",
       "621867   What is the meaning of TQWL7/WL4 in 3A, and wh...       0  \n",
       "155178   Why north Americans are less cultural than peo...       1  \n",
       "807188   What's one thing you did to get your life back...       0  \n",
       "...                                                    ...     ...  \n",
       "145386   What are some of the ways God tests us nowaday...       0  \n",
       "298359   By the way Indians and Chinese hate them selfs...       1  \n",
       "1123644  Why are some people so blinded as to what kind...       1  \n",
       "947768      What are the benefits of eating celery leaves?       0  \n",
       "1121     Approximately how long should it take for some...       0  \n",
       "\n",
       "[161620 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance Dataset\n",
    "pos_data = raw_data[raw_data['target'] == 0]\n",
    "neg_data = raw_data[raw_data['target'] == 1]\n",
    "\n",
    "sample_size = min(len(pos_data), len(neg_data))\n",
    "\n",
    "pos_data = pos_data.sample(sample_size)\n",
    "neg_data = neg_data.sample(sample_size)\n",
    "\n",
    "train_data = pd.concat([pos_data, neg_data]).sample(frac=1)\n",
    "\n",
    "train_data.head()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZMJsJEIzPsw",
    "outputId": "f7d7cf03-7be3-4bfe-a754-793eb2067080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161620, 6349) (161620,)\n"
     ]
    }
   ],
   "source": [
    "# vocab = {word: idx for idx, word in enumerate(own_dict) }\n",
    "import pickle\n",
    "\n",
    "new_vectorizer = CountVectorizer(tokenizer = Tokenizer())\n",
    "new_vectorizer.fit_transform(own_dict)\n",
    "train_vec = new_vectorizer.transform(train_data['question_text'])\n",
    "labels = np.array(train_data['target'])\n",
    "\n",
    "# save vectorizer\n",
    "pickle.dump(new_vectorizer, open('./vectorizer', 'wb'))\n",
    "\n",
    "print(train_vec.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqNFXsSf55M9",
    "outputId": "fc8273b4-43c7-4983-ccd9-56fbdc44bd27"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_vec, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "t1 = time.time()\n",
    "svc = svm.SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"training time:\", (t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuvHtAwlWTX_"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "\n",
    "model_name = \"./svc.model\"\n",
    "pickle.dump(svc, open(model_name, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D53jX7z-cIwi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "49795-Team Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}